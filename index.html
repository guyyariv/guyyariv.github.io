<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
    <meta content="width=device-width, initial-scale=1" name="viewport">

    <!-- Updated Title -->
    <title>Guy Yariv - Generative AI Researcher</title>
    <link rel="icon" href="static/images/favicon.ico"> <!-- Replace with your new favicon -->

    <!-- Meta tags -->
    <meta name="keywords" content="Guy Yariv, Guy, Yariv, Generative AI, Researcher">
    <meta property="og:site_name" content="Guy Yariv">
    <meta property="og:title" content="Guy Yariv - Generative AI Researcher">
    <meta name="description" content="Guy Yariv's Homepage - Generative AI Researcher">
    <meta property="og:description" content="Guy Yariv's Homepage - Generative AI Researcher">
    <meta property="og:image" itemprop="image" content="static/images/profile.jpg">
    <meta property="og:type" content="website" />
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="915">
    <meta property="og:image:height" content="915">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link href="./static/css/fontawesome.all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet">
    <link href="./static/css/bulma.min.css" rel="stylesheet">
    <link href="./static/css/index.css" rel="stylesheet">

    <!-- Custom Styling -->
    <style>
        /* Decrease top/bottom padding of hero and sections */
        .hero.is-small {
            padding: 1.5rem 1.5rem;
        }

        .section {
            padding-top: 2rem;
            padding-bottom: 2rem;
        }

        /* Make publication images bigger by allowing them to fill the column */
        .publication-block .column.is-5 img,
        .publication-block .column.is-6 img {
            width: 100%;
            height: auto;
            object-fit: cover; /* Ensures images maintain aspect ratio */
        }

        /* Optional: reduce margin for the horizontal rule */
        .hr hr {
            margin-top: 0.5rem;
            margin-bottom: 1rem;
        }

        /* Smooth scrolling for internal links */
        html {
            scroll-behavior: smooth;
        }

        /* Custom class to reduce bottom margin of specific paragraph */
        .no-bottom-margin {
            margin-bottom: 0.5rem; /* Adjust this value as needed */
        }

        /* Additional styling for larger images */
        .publication-block .image img {
            border-radius: 8px; /* Optional: add slight rounding for aesthetics */
        }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/index.js"></script>
    <meta name="google-site-verification" content="XzWjTNK8laV1FVIfAcXTgXJD_PMx_xqbTUxjvLCiaXw" />
</head>

<body>

    <section class="hero is-small">
        <div class="hero-body container is-max-desktop">
            <div class="columns is-vcentered">
                <div class="column is-4">
                    <p class="image is-square">
                        <img class="is-rounded" src="./static/images/profile.jpg" alt="Profile Picture of Guy Yariv">
                    </p>
                </div>
                <div class="column">
                    <h1 class="title">
                        <b>Guy Yariv</b>
                    </h1>
                    <div class="content has-text-justified">

                        <!-- 1) Current Status -->
                        <p>
                            I am a PhD student in Computer Science at the
                            <a href="https://www.cs.huji.ac.il/" target="_blank">School of Computer Science and Engineering</a>, Hebrew University of Jerusalem, under the joint supervision of
                            <a href="https://www.cs.huji.ac.il/~adiyoss/" target="_blank">Yossi Adi</a> and
                            <a href="https://sagiebenaim.github.io/" target="_blank">Sagie Benaim</a>.
                        </p>

                        <!-- 2) Experience -->
                        <p>
                            I spent the summer of 2024 and the winter of 2025 as a Research Scientist Intern at Meta (GenAI/MSL)
                            and worked as an AI Researcher at Spot by NetApp from 2022 to 2024.
                        </p>

                        <!-- 3) Research & Passion (specific sentence with reduced spacing) -->
                        <p class="no-bottom-margin">
                            My research interests include machine learning and generative AI. Iâ€™m passionate about achieving full controllability in media generation.
                        </p>

                        <!-- Quick Navigation Links -->
                        <div class="buttons" style="margin-top:1rem;">
                            <a class="button is-small is-link" href="#publications">Publications</a>
                            <a class="button is-small is-link" href="#contact">Contact</a>
                        </div>

                        <!-- Contact Buttons -->
                        <div class="buttons" style="margin-top:1rem;">
                            <a class="external-link button" href="mailto:guy.yariv@mail.huji.ac.il" target="_blank">
                                <span class="icon"><i class="fas fa-envelope"></i></span>
                                <span>Email</span>
                            </a>
                            <a class="external-link button"
                               href="https://scholar.google.com/citations?user=ICzXFf8AAAAJ&hl=en" target="_blank">
                                <span class="icon"><i class="ai ai-google-scholar"></i></span>
                                <span>Google Scholar</span>
                            </a>
                            <a class="external-link button"
                               href="https://www.semanticscholar.org/author/Guy-Yariv/2218332567" target="_blank">
                                <span class="icon"><i class="ai ai-semantic-scholar"></i></span>
                                <span>Semantic Scholar</span>
                            </a>
                            <a class="external-link button" href="https://github.com/guyyariv" target="_blank">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Github</span>
                            </a>
                            <a class="external-link button" href="https://x.com/guy_yariv" target="_blank">
                                <span class="icon"><i class="fab fa-twitter"></i></span>
                                <span>Twitter</span>
                            </a>
                            <a class="external-link button" href="https://www.linkedin.com/in/guy-yariv" target="_blank">
                                <span class="icon"><i class="fa-brands fa-linkedin"></i></span>
                                <span>LinkedIn</span>
                            </a>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <div class="hr">
        <div class="container">
            <hr>
        </div>
    </div>

    <section class="section" id="publications">
        <div class="container is-max-desktop">

            <h2 class="title is-3">Publications</h2>

            <!-- DyPE -->
            <div class="publication-block columns is-vcentered">
                <!-- Enlarged image column -->
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="image">
                        <img src="static/images/dype.png" alt="DyPE." />
                    </p>
                </div>
                <div class="column is-7">
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://noamissachar.github.io/DyPE/" target="_blank">
                                DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion
                            </a>
                        </h3>
                        <div class="publication-venue">Arxiv Preprint</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                Noam Issachar*,
                            </span>
                            <span class="author-block">
                                <strong>Guy Yariv*</strong>,
                            </span>
                            <span class="author-block">
                                Sagie Benaim,
                            </span>
                            <span class="author-block">
                                Yossi Adi,
                            </span>
                            <span class="author-block">
                                Dani Lischinski,
                            </span>
                            <span class="author-block">
                                and Raanan Fattal
                            </span>
                        </div>
                        <p class="publication-description">
                            DyPE lets pre-trained diffusion transformers generate ultra-high-res images (16M+ px) without retraining or extra cost, by matching positional encoding extrapolation to diffusion's shift from low-freq structures to high-freq details.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://noamissachar.github.io/DyPE/" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2510.20766"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://github.com/guyyariv/DyPE"
                               target="_blank">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- DyPE -->


            <!-- TTM -->
            <div class="publication-block columns is-vcentered">
                <!-- Enlarged image column -->
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="image">
                        <img src="static/images/ttm.png" alt="TTM." />
                    </p>
                </div>
                <div class="column is-7"> <!-- Changed from is-8 to is-7 -->
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://guyyariv.github.io/TTM" target="_blank">
                                Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation
                            </a>
                        </h3>
                        <div class="publication-venue">CVPR 2025</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                <strong>Guy Yariv</strong>,
                            </span>
                            <span class="author-block">
                                Yuval Kirstain,
                            </span>
                            <span class="author-block">
                                Amit Zohar,
                            </span>
                            <span class="author-block">
                                Shelly Sheynin,
                            </span>
                            <span class="author-block">
                                Yaniv Taigman,
                            </span>
                            <span class="author-block">
                                Yossi Adi,
                            </span>
                            <span class="author-block">
                                Sagie Benaim,
                            </span>
                            <span class="author-block">
                                and Adam Polyak
                            </span>
                        </div>
                        <p class="publication-description">
                            We propose Through-The-Mask, a two-stage framework for Image-to-Video generation that uses mask-based motion trajectories to enhance object-specific motion accuracy and consistency, achieving state-of-the-art results, particularly in multi-object scenarios.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://guyyariv.github.io/TTM" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2501.03059"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- TTM -->

            <!-- RewardSDS -->
            <div class="publication-block columns is-vcentered">
                <!-- Enlarged image column -->
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="video">
                        <video autoplay loop muted playsinline>
                            <source src="static/images/RewardSDS.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </p>
                </div>
                <div class="column is-7"> <!-- Changed from is-8 to is-7 -->
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://itaychachy.github.io/reward-sds/" target="_blank">
                                RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling
                            </a>
                        </h3>
                        <div class="publication-venue">Arxiv Preprint</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                Itay Chachy,
                            </span>
                            <span class="author-block">
                                <strong>Guy Yariv</strong>,
                            </span>
                            <span class="author-block">
                                Sagie Benaim
                            </span>
                        </div>
                        <p class="publication-description">
                            Introducing RewardSDS, a text-to-3D score distillation method that enhances SDS by using reward-weighted sampling to prioritize noise samples based on alignment scores, achieving fine-grained user alignment.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://itaychachy.github.io/reward-sds/" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2503.09601"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- RewardSDS -->

            <!-- vLMIG -->
            <div class="publication-block columns is-vcentered">
                <!-- Enlarged image column -->
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="image">
                        <img src="static/images/vlmig.png" alt="vLMIG's method." />
                    </p>
                </div>
                <div class="column is-7"> <!-- Changed from is-8 to is-7 -->
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://pages.cs.huji.ac.il/adiyoss-lab/vLMIG/" target="_blank">
                                Improving Visual Commonsense in Language Models via Multiple Image Generation
                            </a>
                        </h3>
                        <div class="publication-venue">Arxiv Preprint</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                <strong>Guy Yariv</strong>,
                            </span>
                            <span class="author-block">
                                Idan Schwartz,
                            </span>
                            <span class="author-block">
                                Yossi Adi*,
                            </span>
                            <span class="author-block">
                                and Sagie Benaim*
                            </span>
                        </div>
                        <p class="publication-description">
                            We improve large language models' visual commonsense by generating multiple images from text prompts and integrating them into decision-making via late fusion, boosting performance on visual commonsense reasoning and NLP tasks.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://pages.cs.huji.ac.il/adiyoss-lab/vLMIG/" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2406.13621"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                            <a class="external-link button is-small is-rounded"
                               href="https://github.com/guyyariv/vLMIG" target="_blank">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- vLMIG -->

            <!-- TempoTokens -->
            <div class="publication-block columns is-vcentered">
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="image">
                        <img src="static/images/tempotokens.png" alt="TempoTokens." />
                    </p>
                </div>
                <div class="column is-7"> <!-- Changed from is-8 to is-7 -->
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://pages.cs.huji.ac.il/adiyoss-lab/TempoTokens/" target="_blank">
                                Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation
                            </a>
                        </h3>
                        <div class="publication-venue">AAAI 2024</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                <strong>Guy Yariv</strong>,
                            </span>
                            <span class="author-block">
                                Itai Gat,
                            </span>
                            <span class="author-block">
                                Sagie Benaim,
                            </span>
                            <span class="author-block">
                                Lior Wolf,
                            </span>
                            <span class="author-block">
                                Idan Schwartz*,
                            </span>
                            <span class="author-block">
                                and Yossi Adi*
                            </span>
                        </div>
                        <p class="publication-description">
                            We propose a method to generate realistic, audio-aligned videos by adapting a text-to-video model with a lightweight adaptor.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://pages.cs.huji.ac.il/adiyoss-lab/TempoTokens/" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2309.16429"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                            <a class="external-link button is-small is-rounded"
                               href="https://github.com/guyyariv/TempoTokens" target="_blank">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- TempoTokens -->

            <!-- AudioToken -->
            <div class="publication-block columns is-vcentered">
                <div class="column is-5"> <!-- Changed from is-4 to is-5 -->
                    <p class="image">
                        <img src="static/images/audiotoken.png" alt="AudioToken." />
                    </p>
                </div>
                <div class="column is-7"> <!-- Changed from is-8 to is-7 -->
                    <div class="content">
                        <h3 class="publication-title">
                            <a href="https://pages.cs.huji.ac.il/adiyoss-lab/AudioToken/" target="_blank">
                                AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation
                            </a>
                        </h3>
                        <div class="publication-venue">InterSpeech 2023</div>
                        <div class="publication-authors">
                            <span class="author-block">
                                <strong>Guy Yariv</strong>,
                            </span>
                            <span class="author-block">
                                Itai Gat,
                            </span>
                            <span class="author-block">
                                Lior Wolf,
                            </span>
                            <span class="author-block">
                                Yossi Adi*,
                            </span>
                            <span class="author-block">
                                and Idan Schwartz*
                            </span>
                        </div>
                        <p class="publication-description">
                            We adapt text-conditioned diffusion models for audio-to-image generation by encoding audio into a token compatible with text representations.
                        </p>
                        <div class="publication-links buttons">
                            <a class="external-link button is-small is-rounded"
                               href="https://pages.cs.huji.ac.il/adiyoss-lab/AudioToken/" target="_blank">
                               <span class="icon"><i class="fas fa-globe-europe"></i></span>
                               <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-rounded" href="https://arxiv.org/abs/2309.16429"
                               target="_blank">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>arXiv</span>
                            </a>
                            <a class="external-link button is-small is-rounded"
                               href="https://github.com/guyyariv/TempoTokens" target="_blank">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <!-- AudioToken -->
        </div>
    </section>

    <!-- Contact Section at the bottom -->
    <section class="section" id="contact" style="padding-top: 1.5rem; padding-bottom: 1.5rem;">
        <div class="container is-max-desktop">
            <h2 class="title is-4">Contact</h2>
            <p>
                Feel free to reach out:
                <br>
                <strong>guyyariv.mail at gmail dot com</strong>
            </p>
        </div>
    </section>

    <div class="hr">
        <div class="container">
            <hr>
        </div>
    </div>

    <!-- Default Statcounter code -->
    <script type="text/javascript">
        var sc_project = 12821411;
        var sc_invisible = 1;
        var sc_security = "57bc5358";
    </script>
    <script type="text/javascript"
        src="https://www.statcounter.com/counter/counter.js"
        async></script>
    <noscript>
        <div class="statcounter"><a title="web stats"
                href="https://statcounter.com/" target="_blank"><img
                    class="statcounter"
                    src="https://c.statcounter.com/12821411/0/57bc5358/1/"
                    alt="web stats"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->

</body>

</html>